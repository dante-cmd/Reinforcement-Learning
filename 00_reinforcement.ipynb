{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "By Hao Dong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **agent** and **enviroment**\n",
    "\n",
    "The environment is an entity that the agent can interact with, e.g. Pong game.\n",
    "\n",
    "The agent controls the paddle to hit the ball back and forth. An agent can ‚Äúinteract‚Äù with the environment by using a predefined **action set**: $A = \\{A_1, A_2, ... \\}$ (all possible actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>The goal of reinforcement learning algorithms is to teach the agent how to interact ‚Äúwell‚Äù with the environment so that the agent is able to obtain a good score under a predefined evaluation metric</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent receive a reward $r$ of $1$ when the ball hits the wall on the opposite side. \n",
    "\n",
    "At an arbitrary time step (a point at which observations can be made), $t$, the agent first observes the current state of the environment, $S_t$, and the corresponding reward value, $R_t$.\n",
    "\n",
    "The agent then decides what to do next based on the state and reward information. The action the agent intends to perform, $A_t$, gets fed back into the environment such that we can obtain the new state $S_{t+1}$ and reward $R_{t+1}$.\n",
    "\n",
    "$$(S_t,R_t) \\rightarrow A_t \\rightarrow (S_{t+1},R_{t+1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation of the environment state $s$($s$ is a general representation of state regardless of time step $t$) from the agent‚Äôs perspective does not always contain all the information about the environment. \n",
    "\n",
    "If the observation only contains partial state information, the environment is *partially observable*. Nevertheless, if the observation contains the complete state information of the environment, the environment is *fully observable*.\n",
    "\n",
    "The action $a$ ($a$ is a general representation of action regardless of time step $t$) is usually conditioned on the state $s$ to represent the behavior of the agent (Under assumption of fully observable environments.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide feedback from the environment to the agent, a reward function $R$ generates an immediate reward $R_t$ according to the environment status and sends it to the agent at every time step. $R_t=R(S_t)$.\n",
    "\n",
    "> Trajectory: \n",
    "> \n",
    "> A **trajectory** is defined: \n",
    "> \n",
    "> $\\tau = (S_0, R_0,  A_0, S_1, R_1, A_1,...)$\n",
    "> \n",
    "> A *trajectory*, being referred to also as an *episode*, is a sequence that goes from the initial state to the terminal state (for finite cases)\n",
    "\n",
    "The initial state in a trajectory, $S_0$, is randomly sampled from the *start-state distribution*, denoted by $œÅ_0$, in which:\n",
    "\n",
    "$$S_0 \\sim œÅ_0(.)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition from a state (after taking an action) to the next state can be either *deterministic transition process* or *stochastic transition process*\n",
    "\n",
    "For the *deterministic transition*, the next state $S_{t+1}$ is governed by a deterministic function:\n",
    "\n",
    "$$S_{t+1} = f(S_t, A_t)$$\n",
    "\n",
    "For the *stochastic transition* process, the next state $S_{t+1}$ is described as a probabilistic distribution:\n",
    "\n",
    "$$S_{t+1} \\sim p(S_{t+1}|S_t, A_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploitation** means maximizing the agent performance using the existing knowledge, and its performance is usually evaluated by the expected reward. Given the actual knowledge, the agent doesn't take risk to explore.\n",
    "\n",
    "The policy he took here is the **greedy policy**, which means the agent constantly performs the action that yields the highest expected reward based on current information, rather than taking risky trials which may lead to lower expected rewards.\n",
    "\n",
    "**Exploration** means increasing existing knowledge by taking actions and interacting with the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov process (MP) is a *discrete stochastic process* with *Markov property*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"assets/markov-process-example.png\" height=360>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph simulates how a person works on two tasks and goes to bed in the end.\n",
    "\n",
    "If I'm doing the \"Task 1\" and exists the `30%` probability of stoping and go to play a \"Game\" and then, the probability of returning to do the \"Task 1\" is only `10%` and the probability of keep playing is `90%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical Model of a Markov Process\n",
    "<center>\n",
    "<img src=\"assets/graphical-model-mp.png\" height=80> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a \\rightarrow b$ indicates the variable $b$ is depended on a vaiable $a$\n",
    "\n",
    "The probabilistic graphical model can help us to have a more intuitive sense of the relationships between variables in reinforcement learning, as well as providing rigorous references when we derive the gradients with respect to different variables along the MP chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MP follows the assumption of **Markov chain** (*memoryless property*) where the next state $S_{t+1}$\n",
    "is only dependent on the current state $S_t$, with the probability of a state\n",
    "jumping to the next state described as follows:\n",
    "\n",
    "$$P(S_{t+1}|S_{t}) = P(S_{t+1}|S_0, ..., S_{t})$$\n",
    "\n",
    "Also the *time homogeneus property*\n",
    "\n",
    "$$P(S_{t+1}|S_{t}) = P(S_{t+2}|S_{t+1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a finite *state set* $S$, we can have *state transition matrix* $P$\n",
    "\n",
    "$ Ôº≥= \\{g, t_1, t_2, r, p, b\\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"assets/matrix-transition.PNG\" height=170>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $P_{i,j}$ represents the probability of transferring the current state $S_i$ to the next state $S_j$.\n",
    "\n",
    "$$ P(s=t_1|s=g)=10\\%$$\n",
    "\n",
    "The sum of each row must be equal to $1$ and the $P$ is always a square matrix.\n",
    "\n",
    "A Markov Process can be represented by a tuple $<Ôº≥, P>$\n",
    "\n",
    "The next state is sample from $P$:\n",
    "\n",
    "$$S_{t+1} \\sim P_{S_t} $$\n",
    "\n",
    "For continuous case a finite matrix can not be used to represent the transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Reward Process\n",
    "\n",
    "We need to add feedback from the enviroment to the agent, so we extent\n",
    "\n",
    "$<Ôº≥, P>$ to $<Ôº≥, P, R, \\gamma>$, in which $R$ represent the *reward function* and $\\gamma$ *reward discount factor*.\n",
    "\n",
    "$$R_t = R(S_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Graphical Model of a Markov Process is updated to \n",
    "<center>\n",
    "<img src=\"assets/graphical-model-mp-reward.png\" height=170>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, if we are considering to move to the next state, we should take account the rewards of the following next states that we will take in order to reach the $T$.\n",
    "\n",
    "If a single trajectory $\\tau$ has $T$ time steps, then **the return** is the cummulative reward discounted by $\\gamma \\in (0,1)$  of a trajectory.\n",
    "\n",
    "$$G_{t=0:T} = G_{t=0}^{(T)} = R(\\tau)_{t=0}^{(T)} = R_0 + \\gamma R_1 + ... + \\gamma^{T} R_T$$\n",
    "\n",
    "where $R_t$ is the **immediate reward** at time step $t$, and $T$ represents the time step of the terminal state and $r$ as a general representation of immediate reward value.\n",
    "\n",
    "The discounted factor is especially critical when handling with infinite MRP cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value function $V(s)$ represents the expected return from the state $S_0$ that take the state value $s$ until final state.\n",
    "\n",
    "<!-- $$V(s) = E[R_t|S_0=s]$$ -->\n",
    "$$V(s) = E[G_{t=0}^{(T)}|S_0=s]$$\n",
    "\n",
    "A simple way to estimate the $V(s)$ is Monte Carlo method, we can randomly sample a large number of trajectories starting from state $s$ according to the given state transition matrix $P$.\n",
    "\n",
    "If the agent acts according to the policy $œÄ$, we denote the *value function* as $V^œÄ(s)$\n",
    "\n",
    "\n",
    "<!-- tasks = ['Bed', 'Game', 'Pass', 'Rest', 'Task1', 'Task2']\n",
    "rewards = {'Bed':0, 'Game':-1, 'Pass':10, 'Rest':1, 'Task1':-2, 'Task2':-2}\n",
    "\n",
    "transition = np.array(\n",
    "    [\n",
    "        [1.0, 0.0, 1.0, 0.0, 0.0, 0.3],\n",
    "        [0.0, 0.9, 0.0, 0.0, 0.3, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.6],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.1],\n",
    "        [0.0, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.9, 0.7, 0.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for tk in  tasks:\n",
    "    n_iter = 1\n",
    "    print(\"V(S={})=\".format(tk), end='')\n",
    "    while n_iter<=10_000:    \n",
    "        array = []\n",
    "        task = tk\n",
    "        target = 'Bed'\n",
    "        G = 0\n",
    "        gamma = 0.9\n",
    "        t = 0\n",
    "        while True:\n",
    "            idx = tasks.index(task)\n",
    "            reward = rewards[task]\n",
    "            G = G + (gamma** t)*reward\n",
    "            t+=1\n",
    "            prob = transition[:, idx].copy()\n",
    "            task = np.random.choice(tasks, p=prob)\n",
    "            if task == target:\n",
    "                array.append(G)\n",
    "                n_iter+=1\n",
    "                break\n",
    "\n",
    "    print(\"{:.3f}\".format(sum(array)/len(array)))} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "tasks = ['Bed', 'Game', 'Pass', 'Rest', 'Task1', 'Task2']\n",
    "rewards = {'Bed':0, 'Game':-1, 'Pass':10, 'Rest':1, 'Task1':-2, 'Task2':-2}\n",
    "value_function = {'Bed':0, 'Game':0, 'Pass':0, 'Rest':0, 'Task1':0, 'Task2':0}\n",
    "\n",
    "transition = np.array(\n",
    "    [\n",
    "        [1.0, 0.0, 1.0, 0.0, 0.0, 0.3],\n",
    "        [0.0, 0.9, 0.0, 0.0, 0.3, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.6],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.1],\n",
    "        [0.0, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.9, 0.7, 0.0]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(task:str, target:str):\n",
    "    def trajectory(task:str, target:str, data:list):\n",
    "        data.append(task)\n",
    "        if task == target:\n",
    "            return data\n",
    "        else:\n",
    "            idx = tasks.index(task)\n",
    "            next_task =np.random.choice(tasks, p=transition[:, idx])\n",
    "            return trajectory(next_task, target, data)\n",
    "\n",
    "    return trajectory(task, target, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    n_iter = 10_000\n",
    "    v = 0\n",
    "    while n_iter > 0:\n",
    "        # 1. Simulating trajectory\n",
    "        simulated_trajectory = get_trajectory(task, 'Bed')\n",
    "\n",
    "        # 2. Simulating rewards\n",
    "        simulated_rewards = np.array([rewards[x] for x in simulated_trajectory])\n",
    "\n",
    "        # 3. Computing return\n",
    "        calculated_return = np.sum(\n",
    "            np.cumprod(\n",
    "                np.ones_like(simulated_rewards)*gamma)/gamma *simulated_rewards)\n",
    "        v = v + calculated_return\n",
    "        n_iter -= 1\n",
    "    n_iter = 10_000\n",
    "    value_function[task] = v/n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bed': 0.0,\n",
       " 'Game': -5.922879947584755,\n",
       " 'Pass': 10.0,\n",
       " 'Rest': 3.9446244226534253,\n",
       " 'Task1': -1.199615908058622,\n",
       " 'Task2': 3.7855726236614347}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent policy usually selects the next state with higher value.\n",
    "\n",
    "E.g. if we are in the *Game* state, we only have, two options: *Game* or *Task1*, we should choice *Task1* (since the higher value of $V(S=\\text{Task1})$). And if we are in th *Task1* state, we would have two options: *Game* or *Task2*.  We should choice *Task2* (since the higher value of $V(S=\\text{Task2})$) and so on.\n",
    "\n",
    "$$\\text{Game} \\rightarrow \\text{Task1} \\rightarrow \\text{Task2} \\rightarrow \\text{Pass} \\rightarrow \\text{Bed}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actions taken above only depend on the expected value of discounted reward  given a state. The action that maximize this expected value is taken. \n",
    "\n",
    "But we do more granularity this expected value and compute at level of action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tuple $$< Ôº≥, P, R, \\gamma>$$ we add $Ôº°$\n",
    "\n",
    "$$< Ôº≥, Ôº°, P, R, \\gamma>$$\n",
    "\n",
    "$$ P(s'|s,a) = P(S_{t+1} = s'|S_{t}=s, A_t=a)$$\n",
    "\n",
    "Where $Ôº°$ represent *finite action set* $\\{a_1, a_2, a_3, ...\\}$ and the immediate reward becomes:\n",
    "\n",
    "$$R_t = R(S_t, A_t)$$\n",
    "\n",
    "A *policy* $\\pi$ represents the way in which the agent behaves based on its observations of the enviroment.\n",
    "\n",
    "$$\\pi(a|s) = p(A_t=a|S_t = s)$$\n",
    "\n",
    "**Expected return** is the expectation of returns over all possible trajectories under a policy. Therefore, **the goal of reinforcement learning is to find the higher expected return by optimizing the policy**.\n",
    "\n",
    "The probability of the T-step trajectory for MDP is:\n",
    "Based on a behavior of the agent will generate a path or trajectory.\n",
    "\n",
    "$$p(\\tau|\\pi)_{t=0}^{T-1} = p_0(S_0) \\prod_{t=0}^{T-1} p(S_{t+1}|S_t, A_t)\\pi(A_t|S_t)$$\n",
    "\n",
    "We are omitting initial state $S_0$. So the probability of the T-step trajectory for MDP is:\n",
    "\n",
    "$$p(\\tau|\\pi)_{t=0}^{T-1} = \\prod_{t=0}^{T-1} p(S_{t+1}|S_t, A_t)\\pi(A_t|S_t)$$\n",
    "\n",
    "Given the reward function $R$ and all possible trajectories $œÑ$, the expected\n",
    "return $J(œÄ)$ starting from state $t=0$ is defined as follows\n",
    "\n",
    "$$J(\\pi) = \\sum_{\\tau} P(\\tau|\\pi)_{t=0}^{T-1} R(\\tau)_{t=0}^{T} = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}]$$\n",
    "\n",
    "The RL optimization problem is to improve the policy for maximizing the expected return with optimization methods. \n",
    "\n",
    "The **optimal policy** $œÄ^‚àó$ can be expressed as\n",
    "\n",
    "$$\\pi^* = \\argmax_{\\pi} J(\\pi)$$\n",
    "\n",
    "Given policy $\\pi$, the **value function** $V(s)$ can be defined as:\n",
    "\n",
    "$$V^{\\pi} (s) = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}|S_{t}=s]$$\n",
    "\n",
    "where $œÑ‚Äâ‚àº‚ÄâœÄ$ means the trajectories $œÑ$ are sampled given the policy $œÄ$\n",
    "\n",
    "In MDP, given an action, we have the **action-value function**, which\n",
    "depends on both the state and the action just taken\n",
    "\n",
    "$$Q^{\\pi} (s, a) = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}|S_{t}=s, A_{t}=a]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to keep in mind that the $Q^œÄ(s, a)$ depends on $œÄ$, as the\n",
    "estimation of the value is an expectation over the trajectories by the policy\n",
    "$œÄ$. This also indicates if the $œÄ$ changes, the corresponding $Q^œÄ(s, a)$ will also change.\n",
    "\n",
    "We therefore usually call the value function estimated with a specific policy *the on-policy value function* (with lower case $q$), for the distinction from\n",
    "the optimal value function estimated with the optimal policy.\n",
    "\n",
    "$$q_{\\pi}(s,a) = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}|S_t=s, A_t=a]$$\n",
    "\n",
    "$$v_{\\pi}(s) = E_{a \\sim \\pi}[q_{\\pi}(s,a)] $$\n",
    "\n",
    "$$v_{\\pi}(s) = \\sum_{a} \\pi(a|s)  q_{\\pi}(s,a) $$\n",
    "<!-- =E_{\\tau \\sim \\pi}[R(\\tau)|S_0=s] -->\n",
    "\n",
    "We can use *Monte Carlo method* to estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman Equation for **Value Function**\n",
    "\n",
    "Given state $s$ in time step $t=0$ ($s'$ in time step $t=1$) with a policy $\\pi$, and the all trajectories $\\tau$ upto time step $T$ with respective rewards, we can define  the value function  $v^{\\pi} (s)$\n",
    "\n",
    "$$v^{\\pi} (s) = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}|S_{t}=s] = \\sum_{\\tau} P(\\tau|\\pi)_{t=0}^{T-1} R(\\tau)_{t=0}^{T} $$\n",
    "\n",
    "\n",
    "\n",
    "We can split the above into \n",
    "1.  $P(\\tau|\\pi)_{t=1}^{T-1} =  P(s'|s,a) \\pi(a|s) P(\\tau|\\pi)_{t=1}^{T-1}$\n",
    "\n",
    "2. $R(\\tau)_{t=0}^{T} = R_0 + \\gamma R(\\tau)_{t=1}^{T}$\n",
    "\n",
    "\n",
    "$$v^{\\pi} (s) = \\sum_{\\tau} P(s'|s,a) \\pi(a|s) P(\\tau|\\pi)_{t=1}^{T-1} [R_0 + \\gamma R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$v^{\\pi} (s) = \\sum_{s'} P(s'|s,a) \\sum_{a} \\pi(a|s) \\sum_{\\tau} P(\\tau|\\pi)_{t=1}^{T-1} [R_0 + \\gamma R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$v^{\\pi} (s) = \\sum_{s'} P(s'|s,a) \\sum_{a} \\pi(a|s)[R_0 + \\gamma \\sum_{\\tau} P(\\tau|\\pi)_{t=1}^{T-1} R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$v^{\\pi} (s) = \\sum_{s'} P(s'|s,a) \\sum_{a} \\pi(a|s)[R_0 + \\gamma v^{\\pi} (s')]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman Equation for **Value Action Function**\n",
    "\n",
    "Let be state $s$ in time step $t=0$ (state $s'$ and action $a'$ in time step $t=1$) with a policy $\\pi$, and the all trajectories $\\tau$ upto time step $T$ with respective rewards, we can define  the value function  $q^{\\pi} (s, a)$\n",
    "\n",
    "$$q^{\\pi} (s, a) = E_{\\tau \\sim \\pi}[R(\\tau)_{t=0}^{T}|S_{t}=s, A_{t}=a] = \\sum_{\\tau} P(\\tau|\\pi)_{t=0}^{T-1} R(\\tau)_{t=0}^{T} $$\n",
    "\n",
    "\n",
    "\n",
    "We can split the above into \n",
    "1.  $P(\\tau|\\pi)_{t=1}^{T-1} =  P(s'|s,a) \\pi(a|s) P(\\tau|\\pi)_{t=1}^{T-1}$\n",
    "\n",
    "2. $R(\\tau)_{t=0}^{T} = R_0 + \\gamma R(\\tau)_{t=1}^{T}$\n",
    "\n",
    "3. Since $s$  and $a$ are given, $\\pi(a|s) = 1$\n",
    "\n",
    "\n",
    "$$q^{\\pi} (s,a) = \\sum_{\\tau} P(s'|s,a) \\pi(a|s) P(\\tau|\\pi)_{t=1}^{T-1} [R_0 + \\gamma R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$q^{\\pi} (s,a) = \\sum_{s'} P(s'|s,a) \\sum_{\\tau} P(\\tau|\\pi)_{t=1}^{T-1}[ R_0 + \\gamma R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$q^{\\pi} (s,a) = \\sum_{s'} P(s'|s,a) [R_0 + \\gamma \\sum_{\\tau} P(\\tau|\\pi)_{t=1}^{T-1} R(\\tau)_{t=1}^{T}]$$\n",
    "\n",
    "$$q^{\\pi} (s, a) = \\sum_{s'} P(s'|s,a) [R_0 + \\gamma v^{\\pi} (s')]$$\n",
    "\n",
    "$$q^{\\pi} (s, a) = \\sum_{s'} P(s'|s,a) [R_0 + \\gamma \\sum_{a'} \\pi(a'|s') q^{\\pi} (s',a')]$$\n",
    "\n",
    "<!-- #### Bellman Ecuation and Optimality\n",
    "\n",
    "Assumptions\n",
    "- Let $x_t$ be the state at same time $t$\n",
    "- The initial decision begin at $t=0$, so the intial state is $x_0$\n",
    "- The set of available actions  that depends on current state $a_t \\in \\Gamma(x_t)$\n",
    "- The next state after taken the action $a_t$ is $x_{t+1}=T(x_t, a_t)$\n",
    "- The payoff from taking the action $a_t$ is $F(x_t,a_t )$\n",
    "- Discount factor $0< \\beta<1$\n",
    "\n",
    "$V(x_0)$ denote the *optimal value* that can be obtained by maximizing this *objetive function* subject to contraints.\n",
    "\n",
    "$$V(x_0) = \\max_{\\{ a_t\\}_{t=0}^{\\infty}} \\sum_{t=0}^{\\infty} \\beta^t F(x_t, a_t)$$\n",
    "\n",
    "*Principle of Optimality*: An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision. (See Bellman, 1957, Chap. III.3.)\n",
    "$$V(x_0) = \\max_{\\{ a_0\\}}[ F(x_0, a_0) +  \\max_{\\{ a_t\\}_{t=1}^{\\infty}}\\sum_{t=1}^{\\infty} \\beta^t F(x_t, a_t)]$$\n",
    "\n",
    "$$V(x_0) = \\max_{\\{ a_0\\}}[F(x_0, a_0)+V(x_1)]$$\n",
    "\n",
    "It reads from inner to outer, first maximize from the step $t=1$ to next, then add the payoff of the initial state and maximize it.  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Value Functions\n",
    "\n",
    "Since on-policy **value functions** are estimated with respect to the policy\n",
    "itself, different policies will lead to different value functions, even for the\n",
    "same set of states and actions. Among all those different value functions,\n",
    "we define the optimal value function as\n",
    "\n",
    "$$v_*(s) = \\max_{\\pi} v_{\\pi}(s)$$\n",
    "\n",
    "For **action-value function**\n",
    "\n",
    "$$q_{*}(s, a) = \\max_{\\pi} q_{\\pi}(s, a)  $$\n",
    "\n",
    "We will update the policy $\\pi$ such that it converges to the optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bellman Optimality Equation\n",
    "\n",
    "Bellman equation for optimal value functions (*Optimal value function* and *Optimal action-value function*)\n",
    "\n",
    "We choose the action (in which we can choose) that maximizes the expected return.\n",
    "\n",
    "Bellman equation for optimal value function\n",
    "\n",
    "$$v^{\\pi}_{*} (s) = \\max_{a} \\sum_{s'} P(s'|s,a) \\sum_{a} \\pi(a|s)[R_0 + \\gamma \\max_{a'} v^{\\pi}_{*} (s')]$$\n",
    "\n",
    "Bellman equation for optimal action-value function\n",
    "\n",
    "The action $a$ is given for time $t=0$ so we can not maximize it.\n",
    "\n",
    "<!-- $$q_{*}(s, a) =\\max_a \\{E[R(s, a) + \\gamma \\max_{a'} q_*(s', a')]\\}$$ -->\n",
    "\n",
    "$$q^{\\pi}_{*} (s, a) = \\sum_{s'} P(s'|s,a) [R_0 + \\gamma \\sum_{a'} \\pi(a'|s') \\max_{a'} q^{\\pi}_{*} (s',a')]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìò Full Explanation of **Dynamic Programming (DP)** in Reinforcement Learning (RL)\n",
    "\n",
    "**Dynamic Programming (DP)** is a fundamental technique in **Reinforcement Learning (RL)** used to solve problems where the agent can model the environment completely ‚Äî that is, when the agent knows all the **transition probabilities** and **reward functions**.\n",
    "\n",
    "It is one of the earliest and most classical approaches to solving **Markov Decision Processes (MDPs)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç What Is Dynamic Programming?\n",
    "\n",
    "In the context of RL:\n",
    "\n",
    "> **Dynamic Programming (DP)** refers to a collection of algorithms that can compute optimal policies **given a perfect model of the environment**, described as a **Markov Decision Process (MDP)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Prerequisites for Using DP\n",
    "\n",
    "To apply DP methods in RL, you need:\n",
    "\n",
    "1. **Full knowledge of the environment**\n",
    "   - Transition probability $ P(s' | s, a) $\n",
    "   - Reward function $ R(s, a, s') $\n",
    "2. The problem must be expressible as an **MDP**\n",
    "3. Sufficient computational resources (DP scales poorly with large state spaces)\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Core Concepts in DP for RL\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **Policy Evaluation** | Estimating the value function $ V^\\pi(s) $ for a given policy $ \\pi $ |\n",
    "| **Policy Improvement** | Improving a policy using the value function |\n",
    "| **Policy Iteration** | Alternating between policy evaluation and improvement |\n",
    "| **Value Iteration** | Directly computing the optimal value function without explicitly maintaining a policy |\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Markov Decision Process (MDP) Recap\n",
    "\n",
    "An MDP is defined by:\n",
    "\n",
    "- A set of **states**: $ \\mathcal{S} $\n",
    "- A set of **actions**: $ \\mathcal{A} $\n",
    "- A **transition probability function**:  \n",
    "  $ P(s' | s, a) = \\text{Probability of moving to state } s' \\text{ from state } s \\text{ after action } a $\n",
    "- A **reward function**:  \n",
    "  $ R(s, a, s') = \\text{Expected reward received after transitioning to } s' \\text{ from } s \\text{ via } a $\n",
    "- A **discount factor**:  \n",
    "  $ \\gamma \\in [0, 1] $ ‚Äî how much future rewards are valued compared to immediate ones\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Bellman Equations: Foundation of DP\n",
    "\n",
    "DP relies on recursive equations known as **Bellman equations**.\n",
    "\n",
    "### ‚úÖ Value Function Under a Policy $ \\pi $\n",
    "\n",
    "$$\n",
    "V^\\pi(s) = \\sum_{a} \\pi(a|s) \\sum_{s'} P(s' | s, a) \\left[ R(s, a, s') + \\gamma V^\\pi(s') \\right]\n",
    "$$\n",
    "\n",
    "This equation expresses the value of being in a state $ s $ under policy $ \\pi $ as the expected sum of current and discounted future rewards.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Types of Dynamic Programming Algorithms\n",
    "\n",
    "### 1. **Policy Evaluation**\n",
    "\n",
    "- **Goal**: Evaluate how good a policy is ‚Äî estimate its value function.\n",
    "- **Method**: Iteratively apply the Bellman expectation backup until convergence:\n",
    "  $$\n",
    "  V_{k+1}(s) = \\sum_a \\pi(a|s) \\sum_{s'} P(s'|s,a)\\left[R(s,a,s') + \\gamma V_k(s')\\right]\n",
    "  $$\n",
    "\n",
    "### 2. **Policy Improvement**\n",
    "\n",
    "- **Goal**: Improve a policy based on its value function.\n",
    "- **Method**: For each state $ s $, choose the action that maximizes expected return:\n",
    "  $$\n",
    "  \\pi'(s) = \\arg\\max_a \\sum_{s'} P(s'|s,a)\\left[R(s,a,s') + \\gamma V^\\pi(s')\\right]\n",
    "  $$\n",
    "\n",
    "### 3. **Policy Iteration**\n",
    "\n",
    "- **Goal**: Find the optimal policy through repeated policy evaluation and improvement.\n",
    "- **Steps**:\n",
    "  1. Initialize a random policy $ \\pi_0 $\n",
    "  2. While policy not converged:\n",
    "     - Evaluate $ V^{\\pi_k}(s) $\n",
    "     - Improve $ \\pi_{k+1} $ using $ V^{\\pi_k} $\n",
    "- **Result**: Converges to the **optimal policy** $ \\pi^* $\n",
    "\n",
    "### 4. **Value Iteration**\n",
    "\n",
    "- **Goal**: Compute the optimal value function directly without needing to evaluate intermediate policies.\n",
    "- **Method**:\n",
    "  $$\n",
    "  V_{k+1}(s) = \\max_a \\sum_{s'} P(s'|s,a)\\left[R(s,a,s') + \\gamma V_k(s')\\right]\n",
    "  $$\n",
    "- After convergence, extract the optimal policy:\n",
    "  $$\n",
    "  \\pi^*(s) = \\arg\\max_a \\sum_{s'} P(s'|s,a)\\left[R(s,a,s') + \\gamma V^*(s')\\right]\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Example: Grid World Problem\n",
    "\n",
    "Let‚Äôs walk through a small **Grid World** example.\n",
    "\n",
    "### üß© Environment\n",
    "\n",
    "- Agent moves in a 4x4 grid.\n",
    "- Goal: Reach terminal states at top-left or bottom-right.\n",
    "- Actions: Up, Down, Left, Right (with 100% accuracy for simplicity).\n",
    "- Rewards: -1 per step (agent wants to reach goal quickly).\n",
    "\n",
    "### Step-by-step DP Application\n",
    "\n",
    "#### 1. **Policy Evaluation**\n",
    "Start with a uniform random policy (equal probability for all actions). Estimate $ V(s) $ for each cell.\n",
    "\n",
    "#### 2. **Policy Improvement**\n",
    "For each cell, select the direction (action) that leads to the highest expected return.\n",
    "\n",
    "#### 3. **Repeat Until Convergence**\n",
    "Alternate between evaluating and improving the policy until no changes occur ‚Äî now we have the **optimal policy**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Advantages of Dynamic Programming\n",
    "\n",
    "| Advantage | Description |\n",
    "|----------|-------------|\n",
    "| **Guaranteed Convergence** | If the MDP is finite and the updates are done correctly, DP converges to the optimal solution |\n",
    "| **Mathematically Exact** | Solves Bellman equations exactly (within numerical precision) |\n",
    "| **Basis for Approximate Methods** | Many modern RL algorithms (like Q-learning, DQN) are inspired by DP concepts |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå Disadvantages of Dynamic Programming\n",
    "\n",
    "| Disadvantage | Description |\n",
    "|--------------|-------------|\n",
    "| **Requires Full Model** | Needs full knowledge of transitions and rewards ‚Äî rarely available in real-world scenarios |\n",
    "| **Computationally Expensive** | Infeasible for large state spaces (curse of dimensionality) |\n",
    "| **Not Suitable for Partial Observability** | Assumes the environment is fully observable (MDP), not applicable to POMDPs |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Comparison with Other RL Approaches\n",
    "\n",
    "| Method | Uses Model? | Planning vs Learning | Exploration Needed? |\n",
    "|-------|-------------|----------------------|----------------------|\n",
    "| **Dynamic Programming** | ‚úÖ Yes | Planning only | ‚ùå No |\n",
    "| **Monte Carlo Methods** | ‚ùå No | Learning from episodes | ‚úÖ Yes |\n",
    "| **Temporal Difference Learning (TD)** | ‚ùå No | Learning from experience | ‚úÖ Yes |\n",
    "| **Q-Learning** | ‚ùå No | Model-free learning | ‚úÖ Yes |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Summary Table\n",
    "\n",
    "| Concept | Description |\n",
    "|--------|-------------|\n",
    "| **Dynamic Programming (DP)** | Used to solve MDPs when the environment model is known |\n",
    "| **Core Methods** | Policy Evaluation, Policy Improvement, Policy Iteration, Value Iteration |\n",
    "| **Key Equation** | Bellman Equation |\n",
    "| **Best Use Case** | Small, discrete MDPs with known dynamics |\n",
    "| **Limitations** | Requires full model; doesn‚Äôt scale well to large environments |\n",
    "\n",
    "---\n",
    "\n",
    "## üßë‚Äçüíª Python Code Example: Value Iteration\n",
    "\n",
    "Here's a simple implementation of **value iteration** for a small MDP:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define environment\n",
    "num_states = 5\n",
    "num_actions = 2\n",
    "gamma = 0.9\n",
    "theta = 1e-6\n",
    "\n",
    "# Simple deterministic transitions and rewards\n",
    "def transition_reward(s, a):\n",
    "    if s == 0:\n",
    "        return (0, 0) if a == 0 else (1, -1)\n",
    "    elif s == 1:\n",
    "        return (0, -1) if a == 0 else (2, -1)\n",
    "    elif s == 2:\n",
    "        return (1, -1) if a == 0 else (3, -1)\n",
    "    elif s == 3:\n",
    "        return (2, -1) if a == 0 else (4, 10)\n",
    "    elif s == 4:\n",
    "        return (4, 0)  # Terminal state\n",
    "\n",
    "# Value Iteration\n",
    "V = np.zeros(num_states)\n",
    "while True:\n",
    "    delta = 0\n",
    "    for s in range(num_states):\n",
    "        v = V[s]\n",
    "        max_q = float('-inf')\n",
    "        for a in range(num_actions):\n",
    "            s_prime, r = transition_reward(s, a)\n",
    "            q = r + gamma * V[s_prime]\n",
    "            max_q = max(max_q, q)\n",
    "        V[s] = max_q\n",
    "        delta = max(delta, abs(v - V[s]))\n",
    "    if delta < theta:\n",
    "        break\n",
    "\n",
    "print(\"Optimal Value Function:\", V)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a **visual walkthrough** of policy/value iteration, or want to see how these methods compare to **model-free reinforcement learning algorithms** like Q-learning or SARSA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Programming(DP) provides a general framework for complex dynamic problems by *breaking* them down into sub-problems. However, DP *requires full knowledge of the environment*, such as the reward model and the transition model, of which we often have limited knowledge in reinforcement learning.\n",
    "\n",
    "Two properties that a *problem* must have for DP to be applicable:\n",
    "1. *Optimal substructure*: Optimal solution can be decomposed into optimal solutions for its sub-problems:\n",
    "2. *Overlapping sub-problems*: implies that the number of sub-problems is finite and the problem ocurr recursively so sub-solutions can be cached and reused.\n",
    "\n",
    "> Recursion is a programming technique that uses functions to solve problems by breaking them down into smaller, more manageable problems. It's a method that involves a function calling itself repeatedly until a base case is reached\n",
    "\n",
    "Policy Iteration: aims to manipulate the policy directly. We can evaluate it by applying the Bellman ecuation recusively:\n",
    "\n",
    "$$v_{\\pi}(s)  = E_{\\pi}[R_t +  \\gamma v_{\\pi (S_{t+1})}|S_t = s ]$$\n",
    "\n",
    "A natural idea to obtain a better policy is\n",
    "acting greedily with respect $v_{\\pi}$\n",
    "\n",
    "$$\\pi{'}(s) = \\argmax_{a \\in A} q_{\\pi}(s, a)$$\n",
    "\n",
    "The first called *Policy evaluation* and the second *Policy improvement* and thogeter is called *generalize policy iteration* (GPI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Policy iteration** consists of two simultaneous, interacting processes, one making the value function consistent with the current policy (policy > evaluation), and the other making the policy greedy with respect to the current value function (policy improvement). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo\n",
    "\n",
    "\n",
    "- MC is a method that only need a little prior knowledge about environment + sampling to know the full the environment.\n",
    "- That means, MC only needs experience for learning.\n",
    "- when using MC in reinforcement learning, we will\n",
    "average the rewards for each state-action pair from different episodes\n",
    "\n",
    "\n",
    "##### First-visit MC prediction\n",
    "*Task*: estimate the state-value function for a given policy œÄ. We will average the returns from a particular policy\n",
    "\n",
    "There are two types of estimations, *First-visit MC* and *every-visit MC*. The *First-visit MC* only considers the return of the First visit to state $s$ in the whole episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv:\n",
    "    def __init__(self):\n",
    "        self.states = [(i, j) for i in range(5) for j in range(5)]\n",
    "        self.goal = (4, 4)\n",
    "        self.state = (0, 0)\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.state\n",
    "        if action == 0: y += 1  # Right\n",
    "        elif action == 1: y -= 1  # Left\n",
    "        elif action == 2: x += 1  # Down\n",
    "        elif action == 3: x -= 1  # Up\n",
    "        # The the agent keep in the same state if \n",
    "        # the action inplies over the max or min values of the enviroment\n",
    "        self.state = (max(0, min(x, 4)), max(0, min(y, 4)))\n",
    "\n",
    "        reward = 1 if self.state == self.goal else -0.01\n",
    "        done = self.state == self.goal\n",
    "        return self.state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0.17960524111619003,\n",
      " (0, 1): 0.28354628411000005,\n",
      " (0, 2): 0.32616253790000005,\n",
      " (0, 3): 0.4261265900000001,\n",
      " (0, 4): 0.3735139310000001,\n",
      " (1, 0): 0.21067249012910003,\n",
      " (1, 1): 0.24519165569900003,\n",
      " (1, 2): 0.5495390000000001,\n",
      " (1, 3): 0.6217100000000001,\n",
      " (1, 4): 0.4845851000000001,\n",
      " (2, 0): 0.3735139310000001,\n",
      " (2, 1): 0.4845851000000001,\n",
      " (2, 2): 0.6217100000000001,\n",
      " (2, 3): 0.7019000000000001,\n",
      " (2, 4): 0.791,\n",
      " (3, 0): 0.17960524111619003,\n",
      " (3, 1): 0.15164471700457102,\n",
      " (3, 2): 0.0834489986963323,\n",
      " (3, 3): 0.791,\n",
      " (3, 4): 0.89,\n",
      " (4, 0): 0.10383222077370254,\n",
      " (4, 1): 0.12648024530411392,\n",
      " (4, 2): 0.06510409882669907,\n",
      " (4, 3): 0.89,\n",
      " (4, 4): 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize environment and V-table\n",
    "env = CustomEnv()\n",
    "\n",
    "# Initialize V-table\n",
    "v_table = {}\n",
    "\n",
    "# Training parameters\n",
    "# learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "# epsilon = 0.1\n",
    "\n",
    "for idx in range(10000):\n",
    "    # print(idx)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode =  []\n",
    "    visited_states = set()\n",
    "    return_sum = {state: 0 for state in env.states}\n",
    "    return_count = {state: 0 for state in env.states}\n",
    "    #{state: [0, 0, 0, 0] for state in env.states}\n",
    "    while not done:\n",
    "        # police\n",
    "        action = random.choice(env.actions)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        episode.append((env.state, reward, done))\n",
    "        # state = next_state\n",
    "\n",
    "    G = 0\n",
    "    for item in reversed(episode):\n",
    "        \n",
    "        state, reward, _ = item\n",
    "        if state not in visited_states:\n",
    "            visited_states.add(state)   \n",
    "            G = reward + discount_factor * G\n",
    "            return_sum[state] += G\n",
    "            return_count[state] += 1\n",
    "            v_table[state] = return_sum[state]/return_count[state]\n",
    "\n",
    "pprint(v_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monte Carlo Control\n",
    "\n",
    "The greedy policy will always choose the action that\n",
    "has maximal value for a given state. We will make use of a greedy policy for the action-value. \n",
    "\n",
    "For each policy improvement, we will need to construct $œÄ_{t+1}$ based on $\\pi_t$ .\n",
    "\n",
    "$$\\pi = \\argmax_a q(s, a) $$\n",
    "\n",
    "$$q_{\\pi_t}(s, \\pi_{t+1}(s)) = \\argmax_a q(s, a) \\ge q_{\\pi_t}(s, \\pi_t(s)) $$\n",
    "\n",
    "##### Incremental Monte Carlo \n",
    "\n",
    "Exists a more efficient computational method that allow us get rid of the list of observed return and simplify the mean calculation step.\n",
    "\n",
    "We will thus do the updated episode by episode.\n",
    "\n",
    "Let $Q(S_t, A_t)$ be the estimation of the state-action value after it has been selected for $t-1$ times (episodes) can be rewitten as:\n",
    "\n",
    "$$Q_{t-1} = \\frac{G_1 + G_2 + ..., G_{t-1}}{t-1} $$\n",
    "\n",
    "This can be computed by the following:\n",
    "\n",
    "$$Q_{t} = \\frac{1}{t} \\sum_{i=1}^{t}G_i$$\n",
    "$$=\\frac{1}{t}(G_t +  \\frac{(t-1)}{(t-1)}\\sum_{i=1}^{t-1}G_i)$$\n",
    "$$=\\frac{1}{t}(G_t +  (t-1)Q_{t-1})$$\n",
    "$$=Q_{t-1} + \\frac{1}{t}(G_t - Q_{t-1})$$\n",
    "\n",
    "More general form:\n",
    "\n",
    "$$ \\text{NewEstimate} \\leftarrow \\text{OldEstimate} + \\text{StepSize}.(\\text{Target} - \\text{OldEstimate}) $$\n",
    "\n",
    "The ‚ÄúStepSize‚Äù is a parameter that controls how fast the estimate is\n",
    "being updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Difference Learning\n",
    "\n",
    "Temporal Difference (TD) combines ideas from DP and MC.\n",
    "\n",
    "Similar to DP, TD use bootstrapping in the estimation (updating estimates based on other estimates, rather than waiting for the final outcome), however, like MC, it does not require full knowegde of the enviroment in th learning in the learning process, but applies a sampling-based optimization approach.\n",
    "\n",
    "TD utilizes the error, the difference between the *target value* and the *estimate value* at different time step TD(0).\n",
    "\n",
    "$$V(S_t) \\leftarrow V(S_t) + \\alpha[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)]$$\n",
    "\n",
    "If we observe carefully, the target value during update for\n",
    "MC is $G_t$ which is known only after one episode. whereas for TD the target\n",
    "value is $R_{t+1}‚Äâ+‚ÄâŒ≥V‚Äâ(S_{t+1})$ which can be computed step by step.\n",
    "\n",
    "**Sarsa: On-Policy TD Control**\n",
    "\n",
    "The update rule can, therefore, be framed as\n",
    "\n",
    "$$Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha[R_{t+1} + \\gamma Q(S_{t+1}, A_t) - Q(S_t, A_t)]$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><thead><tr><th>Aspect</th><th>On-Policy (e.g., SARSA)</th><th>Off-Policy (e.g., Q-Learning)</th></tr></thead><tbody><tr><td><strong>Behavior vs. Target Policy</strong></td><td>Same policy for learning and acting</td><td>Different policies for learning and acting</td></tr><tr><td><strong>Exploration</strong></td><td>Directly updates using exploratory actions</td><td>Updates using the greedy (optimal) action</td></tr><tr><td><strong>Learning Stability</strong></td><td>More stable and robust</td><td>Can be unstable without proper safeguards</td></tr><tr><td><strong>Learning Speed</strong></td><td>Slower due to learning from exploratory actions</td><td>Faster because it learns the optimal policy</td></tr><tr><td><strong>Sample Efficiency</strong></td><td>Lower</td><td>Higher</td></tr><tr><td><strong>Use Case</strong></td><td>Evaluating or improving the current behavior</td><td>Learning the best policy, even while exploring</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-Learning: Off-Policy TD Control**\n",
    "\n",
    "Q-learning is an off-policy TD method that is very similar to Sarsa and plays\n",
    "an important role in deep reinforcement learning application such as the\n",
    "deep Q-network\n",
    "\n",
    "\n",
    "$$Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha[R_{t+1} + \\gamma \\max_a(Q(S_{t+1}, a)) - Q(S_t, A_t)]$$\n",
    "\n",
    "The main difference that Q-learning has from Sarsa is that the target value now is no longer dependent on the policy being used (how the action is chosen) but only on the state-action function (max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Trained Q-Table:'\n",
      "{(0, 0): [0.4261265899999825,\n",
      "          0.20430841017696696,\n",
      "          0.26988027762074734,\n",
      "          0.24933425939289922],\n",
      " (0, 1): [0.24272096171333535,\n",
      "          0.2070055395543572,\n",
      "          0.4845850999999959,\n",
      "          0.23608708290459007],\n",
      " (0, 2): [-0.009619450402373109,\n",
      "          0.033501489096055555,\n",
      "          0.4941230037676856,\n",
      "          -0.00956179249911955],\n",
      " (0, 3): [-0.00702190387,\n",
      "          -0.006375628531738719,\n",
      "          -0.006222977271038711,\n",
      "          -0.0058519850599],\n",
      " (0, 4): [-0.00490099501, -0.00520441888699, -0.0053416828, -0.00490099501],\n",
      " (1, 0): [0.4670034850861101,\n",
      "          0.02690248265109381,\n",
      "          -0.014941567169801955,\n",
      "          -0.01420430159947346],\n",
      " (1, 1): [0.5495389999999978,\n",
      "          0.281588449069307,\n",
      "          0.37096672165404077,\n",
      "          0.3054947869955743],\n",
      " (1, 2): [0.11302993450282967,\n",
      "          0.3709290976292174,\n",
      "          0.621709999999998,\n",
      "          0.20316436608149402],\n",
      " (1, 3): [-0.0036991000000000003,\n",
      "          -0.004250727739,\n",
      "          0.3781869317438103,\n",
      "          -0.00402772591],\n",
      " (1, 4): [-0.0029701, -0.0029701, 0.024190372277221837, -0.003058309],\n",
      " (2, 0): [0.07609659991200401,\n",
      "          -0.009542898323042606,\n",
      "          -0.009595852804621,\n",
      "          -0.011428653290287489],\n",
      " (2, 1): [0.5998485782689155,\n",
      "          -0.004545687104277069,\n",
      "          0.07069148555930925,\n",
      "          0.07861340292910267],\n",
      " (2, 2): [0.4215636020645643,\n",
      "          0.3691427178622258,\n",
      "          0.7018999999999982,\n",
      "          0.290836797781339],\n",
      " (2, 3): [0.07143523386830536, -0.00199, 0.7683762471250394, -0.002071],\n",
      " (2, 4): [0.07942005553355647,\n",
      "          0.02533641141377781,\n",
      "          0.7664255038043417,\n",
      "          -0.0014717479028328998],\n",
      " (3, 0): [-0.0050931710988178945,\n",
      "          -0.0057817049401,\n",
      "          -0.0062242831,\n",
      "          -0.006561343269907079],\n",
      " (3, 1): [0.5138162307533584,\n",
      "          -0.00405629913061,\n",
      "          -0.003668482,\n",
      "          -0.0044005881961],\n",
      " (3, 2): [0.7909999999999986,\n",
      "          0.17676568485171706,\n",
      "          0.18616909175910626,\n",
      "          0.425146475849594],\n",
      " (3, 3): [0.889999999999999,\n",
      "          0.5258452110008007,\n",
      "          0.45704092398048385,\n",
      "          0.37580740251935046],\n",
      " (3, 4): [0.751507892521671,\n",
      "          0.3700978679371475,\n",
      "          0.9999999999999996,\n",
      "          0.43435694187189844],\n",
      " (4, 0): [-0.0041338027000000005, -0.00385219, -0.003940399, -0.004245826672],\n",
      " (4, 1): [0.007183574000000002, -0.002071, -0.0029701, -0.0020791000000000004],\n",
      " (4, 2): [0.506204461060602, -0.001, -0.001, 0.06927613142263524],\n",
      " (4, 3): [0.9353891811077333, 0, 0.023390000000000005, -0.001],\n",
      " (4, 4): [0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "class CustomEnv:\n",
    "    def __init__(self):\n",
    "        self.states = [(i, j) for i in range(5) for j in range(5)]\n",
    "        self.goal = (4, 4)\n",
    "        self.state = (0, 0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.state\n",
    "        if action == 0: y += 1  # Right\n",
    "        elif action == 1: y -= 1  # Left\n",
    "        elif action == 2: x += 1  # Down\n",
    "        elif action == 3: x -= 1  # Up\n",
    "        # The the agent keep in the same state if \n",
    "        # the action inplies over the max or min values of the enviroment\n",
    "        self.state = (max(0, min(x, 4)), max(0, min(y, 4)))\n",
    "\n",
    "        reward = 1 if self.state == self.goal else -0.01\n",
    "        done = self.state == self.goal\n",
    "        return self.state, reward, done\n",
    "\n",
    "# Initialize environment and Q-table\n",
    "env = CustomEnv()\n",
    "\n",
    "# Initialize Q-table\n",
    "# state:[0, 0, 0, 0], point out the Q-values are\n",
    "# zeros for each state and for each action.\n",
    "# The index of [0, 0, 0, 0] represent the actions\n",
    "q_table = {state: [0, 0, 0, 0] for state in env.states}  \n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "epsilon = 0.1\n",
    "\n",
    "def policy(state):\n",
    "    if random.uniform(0, 1) <= epsilon:\n",
    "        # print(\"Explore\")\n",
    "        return random.choice(range(4))\n",
    "    else:\n",
    "        # print(\"Explotation\")\n",
    "        return np.argmax(q_table[state])\n",
    "\n",
    "for episode in range(500):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = policy(state)\n",
    "        # action = np.argmax(\n",
    "        #     q_table[state]) if random.uniform(0, 1) > epsilon else random.choice(range(4))\n",
    "        # 1. Let `state` be the current state\n",
    "        # 2. Based on this we take the action `action`\n",
    "        # 3. This return `next_state` and its `reward` \n",
    "        # 4. Instead take the same action (like SARSA), take the action that max Q\n",
    "        #    not like current policy\n",
    "        next_state, reward, done = env.step(action)\n",
    "        # print(state, action, next_state)\n",
    "        q_table[state][action] += learning_rate * (\n",
    "            reward + discount_factor * max(q_table[next_state]) - q_table[state][action])\n",
    "        state = next_state\n",
    "\n",
    "pprint(\"Trained Q-Table:\")\n",
    "pprint(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "class CustomEnv:\n",
    "    def __init__(self):\n",
    "        self.states = [\"101\", \"102\", \"103\", \"104\", \n",
    "                       \"105\", \"106\", \"107\", \"108\",\n",
    "                       \"109\", \"110\"]\n",
    "        self.goal = 9 # \"110\"\n",
    "        self.state = 0 # \"101\"\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 0 # \"101\"\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        x = self.state\n",
    "        if action == 0: x += 1  # Down\n",
    "        elif action == 1: x -= 1  # Up\n",
    "        # The the agent keep in the same state if \n",
    "        # the action inplies over the max or min values of the enviroment\n",
    "        self.state = max(0, min(x, 9))\n",
    "\n",
    "        reward = 1 if self.state == self.goal else -0.01\n",
    "        done = self.state == self.goal\n",
    "        return self.state, reward, done\n",
    "\n",
    "# Initialize environment and Q-table\n",
    "env = CustomEnv()\n",
    "\n",
    "# Initialize Q-table\n",
    "# state:[0, 0, 0, 0], point out the Q-values are\n",
    "# zeros for each state and for each action.\n",
    "# The index of [0, 0, 0, 0] represent the actions\n",
    "q_table = {state: [0, 0, 0, 0] for state in env.states}  \n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "epsilon = 0.1\n",
    "\n",
    "def policy(state):\n",
    "    if random.uniform(0, 1) <= epsilon:\n",
    "        # print(\"Explore\")\n",
    "        return random.choice(range(4))\n",
    "    else:\n",
    "        # print(\"Explotation\")\n",
    "        return np.argmax(q_table[state])\n",
    "\n",
    "for episode in range(500):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = policy(state)\n",
    "        # action = np.argmax(\n",
    "        #     q_table[state]) if random.uniform(0, 1) > epsilon else random.choice(range(4))\n",
    "        # 1. Let `state` be the current state\n",
    "        # 2. Based on this we take the action `action`\n",
    "        # 3. This return `next_state` and its `reward` \n",
    "        # 4. Instead take the same action (like SARSA), take the action that max Q\n",
    "        #    not like current policy\n",
    "        next_state, reward, done = env.step(action)\n",
    "        # print(state, action, next_state)\n",
    "        q_table[state][action] += learning_rate * (\n",
    "            reward + discount_factor * max(q_table[next_state]) - q_table[state][action])\n",
    "        state = next_state\n",
    "\n",
    "pprint(\"Trained Q-Table:\")\n",
    "pprint(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Learning (DQL)\n",
    "\n",
    "Deep Q-Learning replace Q-Table with a Deep Neural Network (DNN) that approximates the *Q-function*\n",
    "\n",
    "Instead storing Q-values in a table, a NN takes a state a input and output Q-values for all possibles actions.\n",
    "\n",
    "$$Q(s,a, \\theta)=Q^*(s,a)$$\n",
    "\n",
    "where $\\theta$ represent the weights.\n",
    "\n",
    "DQL Algorithm steps:\n",
    "1. Initialize a NN $Q(s, a, \\theta)$ randomly\n",
    "2. For each episode:\n",
    "   * Observe the current state $s$\n",
    "   * Choose an action using an $\\epsilon -\\text{greedy}\\; \\text{policy}$ (explotation vs exploration)\n",
    "   * Excecute $a$, receive reward $r$ and the next state $s'$ \n",
    "   * Sample a batch from the Replay Buffer.\n",
    "   * Compute the Target-Q-value: $y = r + \\gamma \\max_{a'} Q(s', a';\\theta)$\n",
    "   * Compute the Loss: $L = (y - Q(s, a,;\\theta))^2$\n",
    "   * Update NN weights $\\theta$ using backpropagation\n",
    "   * Periodically update target NN $Q(s, a;\\theta)$ to stabilize learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Loss: 0.0000\n",
      "Episode 10, Loss: 0.0188\n",
      "Episode 20, Loss: 0.0001\n",
      "Episode 30, Loss: 0.0001\n",
      "Episode 40, Loss: 0.0010\n",
      "Episode 50, Loss: 0.0011\n",
      "Episode 60, Loss: 0.0002\n",
      "Episode 70, Loss: 0.0002\n",
      "Episode 80, Loss: 0.0003\n",
      "Episode 90, Loss: 0.0002\n",
      "Episode 100, Loss: 0.0002\n",
      "Episode 110, Loss: 0.0000\n",
      "Episode 120, Loss: 0.0000\n",
      "Episode 130, Loss: 0.0000\n",
      "Episode 140, Loss: 0.0001\n",
      "Episode 150, Loss: 0.0000\n",
      "Episode 160, Loss: 0.0000\n",
      "Episode 170, Loss: 0.0000\n",
      "Episode 180, Loss: 0.0000\n",
      "Episode 190, Loss: 0.0000\n",
      "Episode 200, Loss: 0.0000\n",
      "Episode 210, Loss: 0.0000\n",
      "Episode 220, Loss: 0.0000\n",
      "Episode 230, Loss: 0.0000\n",
      "Episode 240, Loss: 0.0000\n",
      "Episode 250, Loss: 0.0000\n",
      "Episode 260, Loss: 0.0000\n",
      "Episode 270, Loss: 0.0000\n",
      "Episode 280, Loss: 0.0000\n",
      "Episode 290, Loss: 0.0000\n",
      "Episode 300, Loss: 0.0000\n",
      "Episode 310, Loss: 0.0000\n",
      "Episode 320, Loss: 0.0000\n",
      "Episode 330, Loss: 0.0000\n",
      "Episode 340, Loss: 0.0000\n",
      "Episode 350, Loss: 0.0000\n",
      "Episode 360, Loss: 0.0000\n",
      "Episode 370, Loss: 0.0000\n",
      "Episode 380, Loss: 0.0000\n",
      "Episode 390, Loss: 0.0000\n",
      "Episode 400, Loss: 0.0000\n",
      "Episode 410, Loss: 0.0000\n",
      "Episode 420, Loss: 0.0000\n",
      "Episode 430, Loss: 0.0000\n",
      "Episode 440, Loss: 0.0000\n",
      "Episode 450, Loss: 0.0000\n",
      "Episode 460, Loss: 0.0000\n",
      "Episode 470, Loss: 0.0000\n",
      "Episode 480, Loss: 0.0000\n",
      "Episode 490, Loss: 0.0000\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# Define Deep Q-Network (DQN)\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Custom environment\n",
    "class CustomEnv:\n",
    "    def __init__(self):\n",
    "        self.states = [(i, j) for i in range(5) for j in range(5)]\n",
    "        self.goal = (4, 4)\n",
    "        self.state = (0, 0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        return self._state_to_tensor()\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.state\n",
    "        if action == 0: y += 1  # Right\n",
    "        elif action == 1: y -= 1  # Left\n",
    "        elif action == 2: x += 1  # Down\n",
    "        elif action == 3: x -= 1  # Up\n",
    "        self.state = (max(0, min(x, 4)), max(0, min(y, 4)))\n",
    "        reward = 1 if self.state == self.goal else -0.01\n",
    "        done = self.state == self.goal\n",
    "        return self._state_to_tensor(), reward, done\n",
    "    \n",
    "    def _state_to_tensor(self):\n",
    "        return torch.tensor([self.state[0] / 4, self.state[1] / 4], dtype=torch.float32)\n",
    "\n",
    "# Hyperparameters\n",
    "epsilon = 0.1  # Exploration factor\n",
    "learning_rate = 0.001\n",
    "discount_factor = 0.9\n",
    "batch_size = 32\n",
    "buffer_capacity = 1000\n",
    "episodes = 500\n",
    "\n",
    "# Initialize environment and networks\n",
    "env = CustomEnv()\n",
    "state_dim = 2  # (x, y) coordinates\n",
    "num_actions = 4\n",
    "\n",
    "policy_net = DQN(state_dim, num_actions)\n",
    "target_net = DQN(state_dim, num_actions)\n",
    "\n",
    "# Both start with the same parameters\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "replay_buffer = deque(maxlen=buffer_capacity)\n",
    "\n",
    "# Training loop\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() < epsilon:\n",
    "            action = random.choice(range(num_actions))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                action = torch.argmax(policy_net(state)).item()\n",
    "        \n",
    "        next_state, reward, done = env.step(action)\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        \n",
    "        # Training the network\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            batch = random.sample(replay_buffer, batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*batch)\n",
    "            \n",
    "            states = torch.stack(states)\n",
    "            actions = torch.tensor(actions, dtype=torch.long)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "            next_states = torch.stack(next_states)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32)\n",
    "            # state => Q_values => Q_value of chosen action (target action)\n",
    "            # Similar to Q_values[state][action]\n",
    "            q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "            # state => Q_values => max Q_value \n",
    "            # Similar to max(Q_values[next_state])\n",
    "            \n",
    "            next_q_values = target_net(next_states).max(1)[0]\n",
    "            # As reward and discount_factor are constant the only parameter\n",
    "            # to update is theta\n",
    "            target_q_values = rewards + discount_factor * next_q_values * (1 - dones)\n",
    "            \n",
    "            # Try to fit the parameter in order to q_values => target_q_values.detach()\n",
    "            # as target_q_values contains the target actions\n",
    "            loss = loss_fn(q_values, target_q_values.detach())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Update target network every 10 episodes\n",
    "    if episode % 10 == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        print(f\"Episode {episode}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2012.13773\n",
    "\n",
    "https://github.com/wassname/rl-portfolio-management?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A----\n",
      "-----\n",
      "-----\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "A----\n",
      "-----\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "A----\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "-A---\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "--A--\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "---A-\n",
      "-----\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "-----\n",
      "---A-\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "-----\n",
      "----A\n",
      "----G\n",
      "\n",
      "-----\n",
      "-----\n",
      "-----\n",
      "-----\n",
      "----A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the Gridworld environment\n",
    "class Gridworld:\n",
    "    def __init__(self, grid_size, start, goal):\n",
    "        self.grid_size = grid_size\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.state = start\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.state\n",
    "        if action == 0:  # Up\n",
    "            next_state = (max(x - 1, 0), y)\n",
    "        elif action == 1:  # Right\n",
    "            next_state = (x, min(y + 1, self.grid_size - 1))\n",
    "        elif action == 2:  # Down\n",
    "            next_state = (min(x + 1, self.grid_size - 1), y)\n",
    "        elif action == 3:  # Left\n",
    "            next_state = (x, max(y - 1, 0))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        reward = 1 if next_state == self.goal else -1\n",
    "        done = next_state == self.goal\n",
    "        self.state = next_state\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.start\n",
    "        return self.state\n",
    "\n",
    "    def render(self):\n",
    "        grid = np.zeros((self.grid_size, self.grid_size), dtype=str)\n",
    "        grid[:, :] = '-'\n",
    "        grid[self.goal] = 'G'\n",
    "        grid[self.state] = 'A'\n",
    "        print(\"\\n\".join([\"\".join(row) for row in grid]) + \"\\n\")\n",
    "\n",
    "# SARSA implementation\n",
    "def sarsa(env, episodes, alpha, gamma, epsilon):\n",
    "    q_table = np.zeros((env.grid_size, env.grid_size, 4))\n",
    "\n",
    "    def choose_action(state, epsilon):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return random.choice(range(4))  # Explore\n",
    "        else:\n",
    "            x, y = state\n",
    "            return np.argmax(q_table[x, y])  # Exploit\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()\n",
    "        action = choose_action(state, epsilon)\n",
    "\n",
    "        while True:\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_action = choose_action(next_state, \n",
    "            )\n",
    "\n",
    "            x, y = state\n",
    "            nx, ny = next_state\n",
    "\n",
    "            # SARSA update rule\n",
    "            q_table[x, y, action] += alpha * (\n",
    "                reward + gamma * q_table[nx, ny, next_action] - q_table[x, y, action]\n",
    "            )\n",
    "\n",
    "            state, action = next_state, next_action\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Parameters\n",
    "grid_size = 5\n",
    "start = (0, 0)\n",
    "goal = (4, 4)\n",
    "episodes = 500\n",
    "alpha = 0.1\n",
    "gamma = 0.99\n",
    "epsilon = 0.1\n",
    "\n",
    "# Initialize and train\n",
    "env = Gridworld(grid_size, start, goal)\n",
    "q_table = sarsa(env, episodes, alpha, gamma, epsilon)\n",
    "\n",
    "# Render final policy\n",
    "state = env.reset()\n",
    "env.render()\n",
    "for _ in range(10):\n",
    "    action = np.argmax(q_table[state])\n",
    "    state, _, done = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class FactoryEnv:\n",
    "    def __init__(self, num_machines:int, job_queue_capacity:int):\n",
    "        self.num_machines = num_machines\n",
    "        self.job_queue_capacity = job_queue_capacity\n",
    "        self.job_queue = []  # List of jobs\n",
    "        self.machines = [0] * num_machines\n",
    "        # Job-0 => Without using\n",
    "        # Job-1:5 => doing some job\n",
    "        self.time = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Takes an action and updates the environment.\"\"\"\n",
    "        job_assigned, machine_id = action\n",
    "\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Process ongoing jobs\n",
    "        self.machines = [max(0, t - 1) for t in self.machines]\n",
    "\n",
    "        # Assign job to machine if valid\n",
    "        # 0\n",
    "        if job_assigned < len(self.job_queue) and self.machines[machine_id] == 0:\n",
    "            self.machines[machine_id] = self.job_queue[job_assigned]\n",
    "            self.job_queue.pop(job_assigned)\n",
    "            reward += 10  # Reward for processing a job\n",
    "\n",
    "        # Negative reward for idle machines\n",
    "        reward -= sum(1 for t in self.machines if t == 0)\n",
    "\n",
    "        # Add new job to queue\n",
    "        if len(self.job_queue) < self.job_queue_capacity:\n",
    "            self.job_queue.append(random.randint(2, 5))  # Job processing time\n",
    "\n",
    "        # Episode ends when time limit is reached or queue overflows\n",
    "        self.time += 1\n",
    "        if self.time >= 100 or len(self.job_queue) >= self.job_queue_capacity:\n",
    "            done = True\n",
    "\n",
    "        # State: machine statuses and job queue\n",
    "        state = np.array(self.machines + self.job_queue + [0] * (self.job_queue_capacity - len(self.job_queue)))\n",
    "        return state, reward, done\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment.\"\"\"\n",
    "        self.job_queue = [random.randint(2, 5) for _ in range(random.randint(1, 3))]\n",
    "        self.machines = [0] * self.num_machines\n",
    "        self.time = 0\n",
    "        state = np.array(self.machines + self.job_queue + [0] * (self.job_queue_capacity - len(self.job_queue)))\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a test scenario\n",
    "def generate_test_data():\n",
    "    test_env = FactoryEnv(num_machines=3, job_queue_capacity=5)\n",
    "    test_env.job_queue = [4, 3, 5]  # Predefined job queue\n",
    "    test_env.machines = [0, 2, 1]  # Machines with some jobs already processing\n",
    "    return test_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best_action(state, policy_net, num_machines):\n",
    "    \"\"\"\n",
    "    Predict the best action given the current state using the trained policy network.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        q_values = policy_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0))\n",
    "        best_action = torch.argmax(q_values).item()\n",
    "        job, machine = divmod(best_action, num_machines)\n",
    "        return job, machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Test Environment\n",
      "Machines: [0, 2, 1]\n",
      "Job Queue: [4, 3, 5]\n",
      "\n",
      "Assigning Job 3 to Machine 0\n",
      "Updated Machines: [3, 1, 0]\n",
      "Updated Job Queue: [4, 5, 2]\n",
      "\n",
      "Assigning Job 4 to Machine 2\n",
      "Updated Machines: [2, 0, 4]\n",
      "Updated Job Queue: [5, 2, 3]\n",
      "\n",
      "Assigning Job 2 to Machine 1\n",
      "Updated Machines: [1, 2, 3]\n",
      "Updated Job Queue: [5, 3, 3]\n",
      "\n",
      "Invalid action detected by the model.\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_env = generate_test_data()\n",
    "state = np.array(test_env.machines + test_env.job_queue + [0] * (test_env.job_queue_capacity - len(test_env.job_queue)))\n",
    "\n",
    "print(\"Initial Test Environment\")\n",
    "print(f\"Machines: {test_env.machines}\")\n",
    "print(f\"Job Queue: {test_env.job_queue}\\n\")\n",
    "\n",
    "while len(test_env.job_queue) > 0:\n",
    "    job, machine = predict_best_action(state, policy_net, test_env.num_machines)\n",
    "    \n",
    "    # Validate the action (ensure the machine is not busy and the job exists in the queue)\n",
    "    if job < len(test_env.job_queue) and test_env.machines[machine] == 0:\n",
    "        print(f\"Assigning Job {test_env.job_queue[job]} to Machine {machine}\")\n",
    "        _, _, done = test_env.step((job, machine))\n",
    "    else:\n",
    "        print(\"Invalid action detected by the model.\")\n",
    "        break\n",
    "\n",
    "    # Update the state\n",
    "    state = np.array(test_env.machines + test_env.job_queue + [0] * (test_env.job_queue_capacity - len(test_env.job_queue)))\n",
    "    print(f\"Updated Machines: {test_env.machines}\")\n",
    "    print(f\"Updated Job Queue: {test_env.job_queue}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.55*3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_forecast = [\n",
    "    [202411, 'Chimbote', 'B00', '16:00 - 17:30', 20, 1],\n",
    "    [202411, 'Chimbote', 'B01RP', '16:00 - 17:30', 19, 1],\n",
    "    [202411, 'Chimbote', 'B02RP', '16:00 - 17:30', 20, 1],\n",
    "    [202411, 'Chimbote', 'B03RP', '16:00 - 17:30', 17, 1]\n",
    "    ]\n",
    "data_aula = [\n",
    "    [202411, 'Chimbote', '101', 18],\n",
    "    [202411, 'Chimbote', '102', 20],\n",
    "    [202411, 'Chimbote', '103', 18],\n",
    "    [202411, 'Chimbote', '104', 18],\n",
    "    [202411, 'Chimbote', '105', 19]\n",
    "    \n",
    "]\n",
    "\n",
    "columns_forecast = ['PERIODO', 'SEDE','CURSO', 'HORARIO', 'FORECAST_ALUMNOS',\n",
    "       'FORECAST_AULAS']\n",
    "columns_aula = ['PERIODO', 'SEDE','AULA', 'AFORO']\n",
    "\n",
    "df_forecast = pd.read_excel(r\"C:\\Users\\dante\\Downloads\\04_MOD_PPTO\\data_forecast.xlsx\", sheet_name='Lima Norte Sat√©lite') \n",
    "# pd.DataFrame(data_forecast, columns=columns_forecast)\n",
    "\n",
    "df_aula = pd.read_excel(r\"C:\\Users\\dante\\Downloads\\04_MOD_PPTO\\Total Aulas.xlsx\", sheet_name='BBDD') #pd.DataFrame(data_aula, columns=columns_aula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aula_normal = df_aula.melt(\n",
    "    id_vars=['SEDE', 'N_AULA', 'YEAR'],\n",
    "    value_vars=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'],\n",
    "    value_name='AFORO',\n",
    "    var_name='MES'\n",
    ")\n",
    "\n",
    "df_aula_normal['PERIODO'] = (\n",
    "    df_aula_normal['YEAR'].astype('string') + \n",
    "    df_aula_normal['MES'].astype('string').str.zfill(2))\n",
    "\n",
    "df_aula_normal.N_AULA = df_aula_normal.N_AULA.astype('string')\n",
    "df_aula_normal.SEDE = df_aula_normal.SEDE.astype('string')\n",
    "df_aula_normal.PERIODO = df_aula_normal.PERIODO.astype('int32')\n",
    "\n",
    "df_aula_consol =df_aula_normal[~(df_aula_normal['AFORO'] == 0) & \n",
    "                               (df_aula_normal['SEDE'] == 'Lima Norte Sat√©lite') &\n",
    "                               (df_aula_normal['PERIODO'] == 202411)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_consol = df_forecast[(df_forecast['FRECUENCIA'] == 'Diario') & (df_forecast['FORECAST_AULAS'] == 1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "5619\n",
      "380\n",
      "0\n",
      "1\n",
      "26771\n",
      "407\n",
      "867\n"
     ]
    }
   ],
   "source": [
    "df_forecast_grouper = df_forecast_consol.groupby(['HORARIO'])\n",
    "\n",
    "array_data_asignacion = []\n",
    "\n",
    "for horario, df_group in df_forecast_grouper:\n",
    "    # print(df_group.shape[0], horario)\n",
    "    \n",
    "    n_aulas = df_group.shape[0]\n",
    "    df_group['IDX'] = range(0, n_aulas)\n",
    "    array_sample = []\n",
    "    start = 1\n",
    "\n",
    "    while start<=100_000:\n",
    "        sample = df_aula_consol.sample(n_aulas, replace=False)\n",
    "        sample['N_ITER'] = start#range(0, n_aulas)\n",
    "        sample['IDX'] = range(0, n_aulas)\n",
    "        array_sample.append(sample)\n",
    "        start+=1\n",
    "\n",
    "    df_sample = pd.concat(array_sample, ignore_index=True)\n",
    "    # print(df_aula_consol)\n",
    "    \n",
    "    df_group_consol = df_group.merge(\n",
    "        df_sample,\n",
    "        on=['PERIODO', 'SEDE', 'IDX'],\n",
    "        how='left'\n",
    "        )\n",
    "    # print(df_group_consol)\n",
    "    df_group_consol['DIFF'] = df_group_consol.eval('AFORO - FORECAST_ALUMNOS')\n",
    "    df_group_consol['REWARD'] = np.where(\n",
    "        df_group_consol.DIFF>=0,1, 0 \n",
    "        #df_group_consol.DIFF,\n",
    "        #np.where(\n",
    "        #    df_group_consol.DIFF == 0, 2 ,\n",
    "        #    1/df_group_consol.DIFF\n",
    "            # np.where(\n",
    "            #     (df_group_consol.DIFF>=0),\n",
    "            #     1/df_group_consol.DIFF,\n",
    "            #    -df_group_consol.DIFF + 6)\n",
    "                ) \n",
    "    #)\n",
    "    # print(horario)\n",
    "    n_iter_max = df_group_consol.groupby(\n",
    "        ['N_ITER']\n",
    "    )['REWARD'].sum().argmax()\n",
    "\n",
    "    print(df_group_consol.groupby(\n",
    "        ['N_ITER']\n",
    "    )['REWARD'].sum().argmax())\n",
    "    array_data_asignacion.append(\n",
    "        df_group_consol[df_group_consol['N_ITER'] == n_iter_max].copy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asignacion = pd.concat(array_data_asignacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['07:00 - 08:30', '08:45 - 10:15', '10:30 - 12:00', '14:15 - 15:45',\n",
       "       '16:00 - 17:30', '17:45 - 19:15', '19:30 - 21:00'], dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_asignacion.HORARIO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>SEDE</th>\n",
       "      <th>FRECUENCIA</th>\n",
       "      <th>CURSO</th>\n",
       "      <th>HORARIO</th>\n",
       "      <th>FORECAST_ALUMNOS</th>\n",
       "      <th>FORECAST_AULAS</th>\n",
       "      <th>IDX</th>\n",
       "      <th>N_AULA</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MES</th>\n",
       "      <th>AFORO</th>\n",
       "      <th>N_ITER</th>\n",
       "      <th>DIFF</th>\n",
       "      <th>REWARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>ALS1</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>ALS2</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>AP1</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>867</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>AP2</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>422</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>AP3</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>314</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>AW2</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>308</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>867</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>AW3</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>410</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B00</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B01RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B04RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B05RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>421</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>867</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B06RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>419</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>867</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B07RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>406</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>867</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B09RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>415</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>867</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>B12RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>316</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>867</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I01RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>402</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I02RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>303</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I03RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>319</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>867</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I04RP</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>322</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>867</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I05</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>325</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>867</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I06</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>418</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>867</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I07</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>318</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I08</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>307</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>867</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I09</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>315</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I10</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>323</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>867</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I11</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>309</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>867</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600866</th>\n",
       "      <td>202411</td>\n",
       "      <td>Lima Norte Sat√©lite</td>\n",
       "      <td>Diario</td>\n",
       "      <td>I12</td>\n",
       "      <td>19:30 - 21:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>413</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>867</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERIODO                 SEDE FRECUENCIA  CURSO        HORARIO  \\\n",
       "866       202411  Lima Norte Sat√©lite     Diario   ALS1  19:30 - 21:00   \n",
       "100866    202411  Lima Norte Sat√©lite     Diario   ALS2  19:30 - 21:00   \n",
       "200866    202411  Lima Norte Sat√©lite     Diario    AP1  19:30 - 21:00   \n",
       "300866    202411  Lima Norte Sat√©lite     Diario    AP2  19:30 - 21:00   \n",
       "400866    202411  Lima Norte Sat√©lite     Diario    AP3  19:30 - 21:00   \n",
       "500866    202411  Lima Norte Sat√©lite     Diario    AW2  19:30 - 21:00   \n",
       "600866    202411  Lima Norte Sat√©lite     Diario    AW3  19:30 - 21:00   \n",
       "700866    202411  Lima Norte Sat√©lite     Diario    B00  19:30 - 21:00   \n",
       "800866    202411  Lima Norte Sat√©lite     Diario  B01RP  19:30 - 21:00   \n",
       "900866    202411  Lima Norte Sat√©lite     Diario  B04RP  19:30 - 21:00   \n",
       "1000866   202411  Lima Norte Sat√©lite     Diario  B05RP  19:30 - 21:00   \n",
       "1100866   202411  Lima Norte Sat√©lite     Diario  B06RP  19:30 - 21:00   \n",
       "1200866   202411  Lima Norte Sat√©lite     Diario  B07RP  19:30 - 21:00   \n",
       "1300866   202411  Lima Norte Sat√©lite     Diario  B09RP  19:30 - 21:00   \n",
       "1400866   202411  Lima Norte Sat√©lite     Diario  B12RP  19:30 - 21:00   \n",
       "1500866   202411  Lima Norte Sat√©lite     Diario  I01RP  19:30 - 21:00   \n",
       "1600866   202411  Lima Norte Sat√©lite     Diario  I02RP  19:30 - 21:00   \n",
       "1700866   202411  Lima Norte Sat√©lite     Diario  I03RP  19:30 - 21:00   \n",
       "1800866   202411  Lima Norte Sat√©lite     Diario  I04RP  19:30 - 21:00   \n",
       "1900866   202411  Lima Norte Sat√©lite     Diario    I05  19:30 - 21:00   \n",
       "2000866   202411  Lima Norte Sat√©lite     Diario    I06  19:30 - 21:00   \n",
       "2100866   202411  Lima Norte Sat√©lite     Diario    I07  19:30 - 21:00   \n",
       "2200866   202411  Lima Norte Sat√©lite     Diario    I08  19:30 - 21:00   \n",
       "2300866   202411  Lima Norte Sat√©lite     Diario    I09  19:30 - 21:00   \n",
       "2400866   202411  Lima Norte Sat√©lite     Diario    I10  19:30 - 21:00   \n",
       "2500866   202411  Lima Norte Sat√©lite     Diario    I11  19:30 - 21:00   \n",
       "2600866   202411  Lima Norte Sat√©lite     Diario    I12  19:30 - 21:00   \n",
       "\n",
       "         FORECAST_ALUMNOS  FORECAST_AULAS  IDX N_AULA  YEAR MES  AFORO  \\\n",
       "866                    13               1    0    403  2024  11     25   \n",
       "100866                 11               1    1    202  2024  11     20   \n",
       "200866                 17               1    2    317  2024  11     14   \n",
       "300866                 17               1    3    422  2024  11     20   \n",
       "400866                 19               1    4    314  2024  11     25   \n",
       "500866                 19               1    5    308  2024  11     23   \n",
       "600866                 14               1    6    410  2024  11     25   \n",
       "700866                 16               1    7    106  2024  11     20   \n",
       "800866                 20               1    8    101  2024  11     20   \n",
       "900866                 17               1    9    201  2024  11     20   \n",
       "1000866                24               1   10    421  2024  11     19   \n",
       "1100866                14               1   11    419  2024  11     19   \n",
       "1200866                25               1   12    406  2024  11     21   \n",
       "1300866                25               1   13    415  2024  11     14   \n",
       "1400866                25               1   14    316  2024  11     24   \n",
       "1500866                18               1   15    402  2024  11     25   \n",
       "1600866                16               1   16    303  2024  11     25   \n",
       "1700866                16               1   17    319  2024  11     10   \n",
       "1800866                22               1   18    322  2024  11     15   \n",
       "1900866                19               1   19    325  2024  11     16   \n",
       "2000866                 8               1   20    418  2024  11     19   \n",
       "2100866                13               1   21    318  2024  11     14   \n",
       "2200866                11               1   22    307  2024  11     17   \n",
       "2300866                14               1   23    315  2024  11     25   \n",
       "2400866                23               1   24    323  2024  11     16   \n",
       "2500866                16               1   25    309  2024  11     20   \n",
       "2600866                10               1   26    413  2024  11     25   \n",
       "\n",
       "         N_ITER  DIFF  REWARD  \n",
       "866         867    12       1  \n",
       "100866      867     9       1  \n",
       "200866      867    -3       0  \n",
       "300866      867     3       1  \n",
       "400866      867     6       1  \n",
       "500866      867     4       1  \n",
       "600866      867    11       1  \n",
       "700866      867     4       1  \n",
       "800866      867     0       1  \n",
       "900866      867     3       1  \n",
       "1000866     867    -5       0  \n",
       "1100866     867     5       1  \n",
       "1200866     867    -4       0  \n",
       "1300866     867   -11       0  \n",
       "1400866     867    -1       0  \n",
       "1500866     867     7       1  \n",
       "1600866     867     9       1  \n",
       "1700866     867    -6       0  \n",
       "1800866     867    -7       0  \n",
       "1900866     867    -3       0  \n",
       "2000866     867    11       1  \n",
       "2100866     867     1       1  \n",
       "2200866     867     6       1  \n",
       "2300866     867    11       1  \n",
       "2400866     867    -7       0  \n",
       "2500866     867     4       1  \n",
       "2600866     867    15       1  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_asignacion[data_asignacion.HORARIO == '19:30 - 21:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>SEDE</th>\n",
       "      <th>CURSO</th>\n",
       "      <th>HORARIO</th>\n",
       "      <th>FORECAST_ALUMNOS</th>\n",
       "      <th>FORECAST_AULAS</th>\n",
       "      <th>IDX</th>\n",
       "      <th>AULA</th>\n",
       "      <th>AFORO</th>\n",
       "      <th>N_ITER</th>\n",
       "      <th>DIFF</th>\n",
       "      <th>REWARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202411</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>B00</td>\n",
       "      <td>16:00 - 17:30</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>202411</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>B01RP</td>\n",
       "      <td>16:00 - 17:30</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>202411</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>B02RP</td>\n",
       "      <td>16:00 - 17:30</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>202411</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>B03RP</td>\n",
       "      <td>16:00 - 17:30</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PERIODO      SEDE  CURSO        HORARIO  FORECAST_ALUMNOS  \\\n",
       "46    202411  Chimbote    B00  16:00 - 17:30                20   \n",
       "146   202411  Chimbote  B01RP  16:00 - 17:30                19   \n",
       "246   202411  Chimbote  B02RP  16:00 - 17:30                20   \n",
       "346   202411  Chimbote  B03RP  16:00 - 17:30                17   \n",
       "\n",
       "     FORECAST_AULAS  IDX AULA  AFORO  N_ITER  DIFF    REWARD  \n",
       "46                1    0  101     18      47    -2 -2.000000  \n",
       "146               1    1  103     18      47    -1 -1.000000  \n",
       "246               1    2  104     18      47    -2 -2.000000  \n",
       "346               1    3  102     20      47     3  0.333333  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecast_consol[df_forecast_consol['N_ITER'] == 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>N_ITER</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERIODO</th>\n",
       "      <th>SEDE</th>\n",
       "      <th>CURSO</th>\n",
       "      <th>HORARIO</th>\n",
       "      <th>FORECAST_AULAS</th>\n",
       "      <th>FORECAST_ALUMNOS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">202411</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Chimbote</th>\n",
       "      <th>B00</th>\n",
       "      <th>16:00 - 17:30</th>\n",
       "      <th>1</th>\n",
       "      <th>20</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01RP</th>\n",
       "      <th>16:00 - 17:30</th>\n",
       "      <th>1</th>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02RP</th>\n",
       "      <th>16:00 - 17:30</th>\n",
       "      <th>1</th>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03RP</th>\n",
       "      <th>16:00 - 17:30</th>\n",
       "      <th>1</th>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "N_ITER                                                                 1   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.0   \n",
       "                 B01RP 16:00 - 17:30 1              19                2.0   \n",
       "                 B02RP 16:00 - 17:30 1              20                2.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                1.0   \n",
       "\n",
       "N_ITER                                                                 2   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.0   \n",
       "                 B01RP 16:00 - 17:30 1              19                1.0   \n",
       "                 B02RP 16:00 - 17:30 1              20               -1.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                1.0   \n",
       "\n",
       "N_ITER                                                                      3   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS             \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.000000   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.000000   \n",
       "                 B02RP 16:00 - 17:30 1              20               -2.000000   \n",
       "                 B03RP 16:00 - 17:30 1              17                0.333333   \n",
       "\n",
       "N_ITER                                                                 4   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.0   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.0   \n",
       "                 B02RP 16:00 - 17:30 1              20               -2.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                0.5   \n",
       "\n",
       "N_ITER                                                                 5   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20                2.0   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.0   \n",
       "                 B02RP 16:00 - 17:30 1              20               -1.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                1.0   \n",
       "\n",
       "N_ITER                                                                 6   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -1.0   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.0   \n",
       "                 B02RP 16:00 - 17:30 1              20                2.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                1.0   \n",
       "\n",
       "N_ITER                                                                 7   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS        \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20                2.0   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.0   \n",
       "                 B02RP 16:00 - 17:30 1              20               -2.0   \n",
       "                 B03RP 16:00 - 17:30 1              17                0.5   \n",
       "\n",
       "N_ITER                                                                      8   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS             \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.000000   \n",
       "                 B01RP 16:00 - 17:30 1              19               -1.000000   \n",
       "                 B02RP 16:00 - 17:30 1              20               -1.000000   \n",
       "                 B03RP 16:00 - 17:30 1              17                0.333333   \n",
       "\n",
       "N_ITER                                                                      9   \\\n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS             \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.000000   \n",
       "                 B01RP 16:00 - 17:30 1              19                2.000000   \n",
       "                 B02RP 16:00 - 17:30 1              20               -2.000000   \n",
       "                 B03RP 16:00 - 17:30 1              17                0.333333   \n",
       "\n",
       "N_ITER                                                                 10  \n",
       "PERIODO SEDE     CURSO HORARIO       FORECAST_AULAS FORECAST_ALUMNOS       \n",
       "202411  Chimbote B00   16:00 - 17:30 1              20               -2.0  \n",
       "                 B01RP 16:00 - 17:30 1              19                1.0  \n",
       "                 B02RP 16:00 - 17:30 1              20               -2.0  \n",
       "                 B03RP 16:00 - 17:30 1              17                0.5  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_forecast_consol, \n",
    "               index=['PERIODO', 'SEDE', 'CURSO', 'HORARIO', 'FORECAST_AULAS', 'FORECAST_ALUMNOS'],\n",
    "               columns=['N_ITER'],\n",
    "               values='REWARD',aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Values:\n",
      "[[94.60880685 95.66546247 96.73279137 97.81090137]\n",
      " [95.66546247 96.73279137 97.81090137 98.89990137]\n",
      " [96.73279137 97.81090137 98.89990137 99.99990137]\n",
      " [97.81090137 98.89990137 99.99990137 99.99990137]]\n",
      "\n",
      "Optimal Policy:\n",
      "‚Üí ‚Üí ‚Üí ‚Üì\n",
      "‚Üí ‚Üí ‚Üí ‚Üì\n",
      "‚Üí ‚Üí ‚Üí ‚Üì\n",
      "‚Üí ‚Üí ‚Üí ‚Üí\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class SimpleGridWorld:\n",
    "    \"\"\"A simple 4x4 grid world to demonstrate Bellman equation.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.grid_size = 4\n",
    "        self.n_states = self.grid_size ** 2\n",
    "        self.n_actions = 4  # up, right, down, left\n",
    "        self.goal_state = self.n_states - 1  # bottom-right corner\n",
    "        \n",
    "        # Initialize transition probabilities and rewards\n",
    "        self.P = self._create_transition_matrix()\n",
    "        self.R = self._create_reward_matrix()\n",
    "    \n",
    "    def _create_transition_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Create transition probability matrix P[s,a,s'].\"\"\"\n",
    "        P = np.zeros((self.n_states, self.n_actions, self.n_states))\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            row, col = s // self.grid_size, s % self.grid_size\n",
    "            \n",
    "            # For each action (up, right, down, left)\n",
    "            for a in range(self.n_actions):\n",
    "                next_row, next_col = row, col\n",
    "                \n",
    "                # Determine next state based on action\n",
    "                if a == 0:  # up\n",
    "                    next_row = max(0, row - 1)\n",
    "                elif a == 1:  # right\n",
    "                    next_col = min(self.grid_size - 1, col + 1)\n",
    "                elif a == 2:  # down\n",
    "                    next_row = min(self.grid_size - 1, row + 1)\n",
    "                elif a == 3:  # left\n",
    "                    next_col = max(0, col - 1)\n",
    "                \n",
    "                next_state = next_row * self.grid_size + next_col\n",
    "                P[s, a, next_state] = 1.0\n",
    "        \n",
    "        return P\n",
    "    \n",
    "    def _create_reward_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Create reward matrix R[s,a,s'].\"\"\"\n",
    "        R = np.full((self.n_states, self.n_actions, self.n_states), -0.1)  # Small negative reward for each step\n",
    "        \n",
    "        # Add positive reward for reaching the goal\n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                if np.any(self.P[s, a] * (self.goal_state == np.arange(self.n_states))):\n",
    "                    R[s, a] = np.where(self.goal_state == np.arange(self.n_states), 1.0, -0.1)\n",
    "        \n",
    "        return R\n",
    "\n",
    "def demonstrate_bellman_optimality():\n",
    "    \"\"\"Demonstrate Bellman optimality equation through value iteration.\"\"\"\n",
    "    env = SimpleGridWorld()\n",
    "    gamma = 0.99  # discount factor\n",
    "    theta = 1e-6  # convergence threshold\n",
    "    \n",
    "    # Initialize value function\n",
    "    V = np.zeros(env.n_states)\n",
    "    \n",
    "    # Initialize policy\n",
    "    policy = np.zeros(env.n_states, dtype=int)\n",
    "    \n",
    "    iteration_history = []\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        V_old = V.copy()\n",
    "        iteration_history.append(V_old.copy())\n",
    "        \n",
    "        # Update each state\n",
    "        for s in range(env.n_states):\n",
    "            v = V[s]\n",
    "            \n",
    "            # Calculate Q-values for all actions\n",
    "            Q_values = np.zeros(env.n_actions)\n",
    "            for a in range(env.n_actions):\n",
    "                for s_next in range(env.n_states):\n",
    "                    # Bellman equation components:\n",
    "                    # 1. P[s,a,s']: Transition probability\n",
    "                    # 2. R[s,a,s']: Immediate reward\n",
    "                    # 3. gamma * V[s']: Discounted future value\n",
    "                    Q_values[a] += env.P[s, a, s_next] * (\n",
    "                        env.R[s, a, s_next] + gamma * V_old[s_next]\n",
    "                    )\n",
    "            \n",
    "            # Update value function with maximum Q-value\n",
    "            V[s] = np.max(Q_values)\n",
    "            # Update policy\n",
    "            policy[s] = np.argmax(Q_values)\n",
    "            \n",
    "            # Track maximum change\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        \n",
    "        # Check convergence\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    return V, policy, iteration_history\n",
    "\n",
    "def visualize_value_iteration(iteration_history: List[np.ndarray], grid_size: int):\n",
    "    \"\"\"Visualize how values evolve during value iteration.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    iterations_to_show = [0, len(iteration_history)//3, 2*len(iteration_history)//3, -1]\n",
    "    \n",
    "    for idx, iter_idx in enumerate(iterations_to_show):\n",
    "        ax = axes[idx//2, idx%2]\n",
    "        values = iteration_history[iter_idx].reshape(grid_size, grid_size)\n",
    "        \n",
    "        im = ax.imshow(values, cmap='viridis')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Add value annotations\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                text = ax.text(j, i, f'{values[i, j]:.2f}',\n",
    "                             ha=\"center\", va=\"center\", color=\"w\")\n",
    "        \n",
    "        ax.set_title(f'Iteration {iter_idx}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Run demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    # Demonstrate Bellman optimality equation\n",
    "    optimal_values, optimal_policy, history = demonstrate_bellman_optimality()\n",
    "    \n",
    "    print(\"\\nOptimal Values:\")\n",
    "    print(optimal_values.reshape(4, 4))\n",
    "    \n",
    "    print(\"\\nOptimal Policy:\")\n",
    "    policy_symbols = ['‚Üë', '‚Üí', '‚Üì', '‚Üê']\n",
    "    policy_grid = [[policy_symbols[optimal_policy[r * 4 + c]] \n",
    "                   for c in range(4)] for r in range(4)]\n",
    "    for row in policy_grid:\n",
    "        print(' '.join(row))\n",
    "    \n",
    "    # Create visualization\n",
    "    plt = visualize_value_iteration(history, 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position of helicopter $\\rightarrow$ how to move control sticks\n",
    "\n",
    "The position and orientation and speed and so on *the state* of the helicopter.\n",
    "\n",
    "an and the task is to find function that maps from the state of the helicopter to the action that should be taken.\n",
    "\n",
    "We can use supervised learning to solve this problem, but this is not the best way to solve it. In actually not exists the right action to take. It's actually very difficult to get a data set of $x$ and the ideal action $y$.\n",
    "\n",
    "Reinforcement learning use the mechanism of reward to solve this problem.\n",
    "The reward is a measure of how good the action was.\n",
    "\n",
    "One of the powerful of reinforcement learning is that *you can tell it what to do* rather than *how to do it* specifying the reward function. This add more flexibility to system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications\n",
    "\n",
    "* Control of robots\n",
    "* Factory optimization:  how do you arrange things in the fatory to maximize throughput?\n",
    "* Stock trading\n",
    "* Playing video games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalism\n",
    "\n",
    "- *state* (s)\n",
    "- *terminal state*\n",
    "- *action* (a)\n",
    "- *reward* (R(s)) if its damage the reward can be negative\n",
    "- *next state* (s')\n",
    "\n",
    "$$(s, a, R(s), s')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return is the sum of discounted future rewards from the current state to target state.\n",
    "\n",
    "$$\\text{Return}(s¬∞ \\rightarrow s^{n}) = R(s¬∞) + \\gamma^{1} R(s^{1}) + ... +  \\gamma^{n} R(s^n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A policy is a function $\\pi(s)=a$ that maps from state to action. And we want to find is **a policy that maximizes the expected return**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) function is a function that maps from state and action to return.\n",
    "\n",
    "This return is the sum of discounted future rewards from the current state + action taken + optimal target state.\n",
    "\n",
    "$$R(s) + \\gamma R(s^1) + \\gamma^2 R(s^2) + ... + \\gamma^n R(s^n)$$\n",
    "\n",
    "Here $R(s)$ is the reward of state $s$, and $\\gamma$ is the discount factor. $R(s^1)$ is the reward of state $s^1$ after taking action $a$, and from $R(s^2)$ to $R(s^n)$ is the policy that maximizes the expected return.\n",
    "\n",
    "The best possible *return* and the best *action* from the state $s$ is $\\max_{a} Q(s,a)$\n",
    "\n",
    "$Q(s,a) = $ Return if you\n",
    "- start in state $s$\n",
    "- take the action $a$\n",
    "- then behave optimally ater that.\n",
    "\n",
    "$Q$ function is called Optional $Q^{*}$ function as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman ecuation\n",
    "\n",
    "$Q (s,a) = R(s,a) + \\gamma \\max_{a'} Q(s',a')$\n",
    "\n",
    "Bellman ecuation with random stochastic environment\n",
    "\n",
    "$Q (s,a) = R(s,a) + \\gamma E[\\max_{a'} Q(s',a')]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete State Space: The space is discrete.\n",
    "\n",
    "Continuous State Space: The space is continuous. and in real world the dimension of the state is $\\mathbb{R}^{n}$.\n",
    "\n",
    "For example: a car has $3$ states related to movement, but i has $3$ states related to acceleration.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "x\\\\\n",
    "y \\\\\n",
    "\\theta \\\\\n",
    "\\dot{x} \\\\\n",
    "\\dot{y} \\\\\n",
    "\\dot{\\theta} \n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luna lander\n",
    "\n",
    "actions:\n",
    "* do nothing\n",
    "* left thruster\n",
    "* right thruster\n",
    "* main thruster\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "x\\\\\n",
    "y \\\\\n",
    "\\theta \\\\\n",
    "\\dot{x} \\\\\n",
    "\\dot{y} \\\\\n",
    "\\dot{\\theta} \\\\\n",
    "l\\\\\n",
    "r\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "$x$ how far to left or right\n",
    "\n",
    "$y$ how far to up or down\n",
    "\n",
    "$\\dot{x}$ velocity how fast moving in the horizontal direction\n",
    "\n",
    "$\\dot{y}$ velocity how fast moving in the vertical direction\n",
    "\n",
    "$\\theta$ is the lunar lander *tilted* to the left or right\n",
    "\n",
    "$\\dot{\\theta}$ is the angular velocity\n",
    "\n",
    "$l$: $1$ if the left leg is sitting on the ground otherwise $0$\n",
    "\n",
    "$r$: $1$ if the right leg is sitting on the ground otherwise $0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Function\n",
    "\n",
    "* Getting to landing pad: $100-140$\n",
    "* Additional reward for moving toward/way form pad\n",
    "* crash: $-100$\n",
    "* soft landing: $+100$\n",
    "* leg grounded: $+10$\n",
    "* fire main engine: $-0.3$\n",
    "* fire side thrusters: $-0.03$\n",
    "\n",
    "Last two penalties the using of the left and right thrusters.\n",
    "\n",
    "Lunar Lander Problem\n",
    "\n",
    "Learn a policy that maximizes the expected return, given \n",
    "\n",
    "$$s = \\begin{bmatrix}\n",
    "x\\\\\n",
    "y \\\\\n",
    "\\theta \\\\\n",
    "\\dot{x} \\\\\n",
    "\\dot{y} \\\\\n",
    "\\dot{\\theta} \\\\\n",
    "l\\\\\n",
    "r\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "pick action $a = \\pi(s)$ so as to maximize the return\n",
    "\n",
    "$\\gamma = 0.985$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning\n",
    "\n",
    "Input: $x = [s^{T}, a_{\\text{one hot}}]$\n",
    "\n",
    "The accion $a$ is one hot encoded.\n",
    "\n",
    "sample: $[x, y, \\theta, \\dot{x}, \\dot{y}, \\dot{\\theta}, l, r, 1, 0, 0,0]$\n",
    "\n",
    "\n",
    "Output: $Q(s, a)=y$\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"Screenshot 2024-07-11 194604.png\" width=\"600px\">\n",
    "</div>\n",
    "\n",
    "In the state $s$, use neural network to compute\n",
    "\n",
    "$Q(s, \\text{nothing})$, $Q(s, \\text{left})$, $Q(s, \\text{main})$, $Q(s, \\text{right})$\n",
    "\n",
    "Pick the action $a$ that maximizes $Q(s, a)$\n",
    "\n",
    "[Deep Q-Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Algorithm\n",
    "\n",
    "Intitialize NN randonmly as guess of $Q(s, a)$\n",
    "\n",
    "Repeat {\n",
    "    Take actions in the lunar lander. Get $(s,a, R(s), s')$\n",
    "    Store 10, 00 most recent $(s,a, R(s), s')$ tuples.\n",
    "    Train NN:\n",
    "Create training set of 10,000 examples using $x=(s, a)$ and $y = R(s) + \\gamma \\max_{a'} Q(s',a')$ \n",
    "Train $Q_{\\text{New}}$ such that $Q_{\\text{New}}(s,a) = y$\n",
    "    Set $Q = Q_{\\text{New}}$\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "ss = deque(maxlen=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.append((5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.append((9, 5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([5, (9, 5, 6)], maxlen=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement in efficiency.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"Screenshot 2024-07-11 201234.png\" width=\"400px\">\n",
    "</div>\n",
    "\n",
    "In the state $s$, input $s$ to NN. Pick the action $a$ that maximizes $Q(s, a)$\n",
    "\n",
    "The Bellman equation is compute mroe effiecient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How  to choose actions while still learning?\n",
    "\n",
    "In some state $s$:\n",
    "\n",
    "* Option 1: Pick the action $a$ that maximizes $Q(s, a)$\n",
    "* Option 2 [$\\epsilon$ -greedy policy]: \n",
    "  - With the probability $1 - \\epsilon$ pick the action $a$ that maximizes $Q(s, a)$. *Greedy*, or *Exploitation*.\n",
    "  - With the probability $\\epsilon=\\%5$ pick a random action. *Exploration*\n",
    "\n",
    "\n",
    "It guarantees that the policy will not be stuck in a local minimal, or local optima. It guarantees that the policy not biases that action to some actions with low penalty.\n",
    "\n",
    "Strategy: $\\epsilon$ high for starting and $\\epsilon$ low for ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning in reforcement learning is hard to do. And the effect of wrong parameter tunning increase the time x10 to convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
